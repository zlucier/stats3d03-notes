\rhead{\color{main}1 Review}
\section{Review}

We begin our discussion of mathematical statistics with a review of concepts from previous courses. One of these key concepts is that of probability.

\subsection{Probability}

Recall that a \textbf{sample space} $\Omega$ is the set of all possible outcomes of an experiment. Subsets of $\Omega$ are called \textbf{events} and the collection of all events is denoted by $\mathcal F$.

\begin{definition}[probability set function]
	Let $\Omega$ be a sample space and let $\mathcal F$ be the collection of all events. Let $P:\mathcal F\to\mathbb R$ be a real-valued function. Then $P$ is a \textbf{probability set function} (also referred to as \textbf{probability measure}, \textbf{probability distribution} or simply \textbf{probability}) if it satisfies the following three conditions:
	\begin{enumerate}
		\item $0\leq P(A)\leq 1$, for all $A\in\mathcal F$.
		\item $P(\Omega)=1$ and $P(\emptyset)$.
		\item If $\{A_n\}$ is a sequence of events in $\mathcal F$ and $A_m\cap A_n=\emptyset$ for all $m\neq n$, then

		$$P\left(\bigcup_{i=1}^\infty A_i\right)=\sum_{i=1}^\infty P(A_i)$$
	\end{enumerate}
\end{definition}

In order to formalize quantities which depend on random events, we reintroduce the concept of a random variable and its support.

\begin{definition}[random variable]
	Let $\Omega$ be a sample space. A \textbf{random variable} is a function from $\Omega$ into the real numbers. The \textbf{support} (also called \textbf{space} or \textbf{range}) of $X$ is the set of real numbers $\mathcal S=\{x:x=X(\omega),\omega\in \Omega\}$.
\end{definition}

In cases where $\mathcal S$ is a countable set, we say that $X$ is a \textbf{discrete random variable}. The set $\mathcal S$ may also be an interval of real numbers, in which case we say that $X$ is a \textbf{continuous random variable}.

Given a random variable $X$, its support $\mathcal S$ becomes the sample space of interest. Besides inducing the sample space $\mathcal S$, $X$ also induces a probability which we call the \textbf{distribution} of $X$.

The probability distribution of a discrete random variable is described completely in terms of its probability mass function and its support.

\begin{definition}[pmf]
	Let $X$ be a discrete random variable with support $\mathcal S$. The \textbf{probability mass function} (pmf) of $X$ $p_X$ is given by
$$p_X(x) = P(X = x),\text{ for }x \in \mathcal S.$$
\end{definition}

Similarly, the probability distribution of a continuous random variable is described completely in terms of its probability density function and its support.

\begin{definition}[pdf]
	Let $X$ be a continuous random variable with support $\mathcal S$. The \textbf{probability density function} (pdf) of $X$ is a function $f_X$ that satisfies
$$P(X\leq x)=\int_{-\infty}^xf_X(t)\dd t$$
for all $x\in\mathcal S$.
\end{definition}

The pmf of a discrete random variable and the pdf of a continuous random variable are quite different entities. The cumulative distribution function, though, uniquely determines the probability distribution of a random variable.

\begin{definition}[cdf]
	Let $X$ be a random variable. Then its \textbf{cumulative distribution function} (cdf) is defined by $F_X(x)$, where
$$F_X(x)=P(X\leq x).$$
\end{definition}

\subsection{Expectation}

One of the most important measures associated with random variables is that of expectation.

\begin{definition}[expectation]
	Let $X$ be a random variable with support $\mathcal S$.

	If $X$ is a \textit{continuous} random variable with pdf $f(x)$ and
	$$\int_{-\infty}^{\infty}|x|f(x)\dd x$$
	is finite, then the \textbf{expectation} of $X$, denoted $E(X)$ is defined as
	$$E(X)=\int_{-\infty}^{\infty} xf(x)\dd x.$$ 

	If $X$ is a \textit{discrete} random variable with pmf $p(x)$ and
	$$\sum_{x\in\mathcal S}|x|p(x)$$
	is finite, then the \textbf{expectation} of $X$ is defined as
	$$E(X)=\sum_{x\in\mathcal S}xp(x).$$
\end{definition}

Sometimes the expectation $E(X)$ is called the \textbf{expected value} of $X$ or the \textbf{mean} of $X$. When the mean designation is used, we often denote the expected value by $\mu$.

\begin{theorem}[Law of the unconscious statistician]
	Let $X$ be a random variable with support $\mathcal S_X$ and let $Y=g(X)$ for some real-valued function $g$.
	\begin{enumerate}[label=\color{main}(\alph*)]
		\item Suppose $X$ is discrete with pmf $p_X(x)$. If $$\sum_{x\in\mathcal S_X}|g(x)|p_X(x)$$ is finite, then the expectation of $Y$ exists and is given by $$E(Y)=\sum_{x\in\mathcal S_X}g(x)p_X(x).$$
		\item Suppose $X$ is continuous with pdf $f_X(x)$. If $$\int_{-\infty}^{\infty}|g(x)|f_X(x)\dd x$$ is finite, then the expectation of $Y$ exists and is given by $$E(Y)=\int_{-\infty}^{\infty}g(x)f_X(x)\dd x.$$
	\end{enumerate}
\end{theorem}

An important application of the above theorem shows that expectation is \textit{linear}. That is, $E(aX+b)=aE(X)+b$. It is a useful exercise to show that this is the case. Furthermore, this property can be generalized for $a_1,\hdots,a_k$ real numbers and $g_1,\hdots,g_k$ real-valued functions.
$$E(a_1g_1(X)+\cdots+a_kg_k(X))=a_1E(g_1(X))+\cdots+a_kE(g_k(X))$$

\subsection{Moments}

Expectation allows us to define a countably infinite number of measures associated with random variables, called moments.

\begin{definition}[moment]
	Suppose $X$ is a random variable and $m$ is a positive integer. The \textbf{$m$th moment} of $X$ is defined to be $E(X^m)$, provided this expectation exists.
\end{definition}

As such, the first moment of a random variable is simply its \textbf{mean} $\mu$. It is often useful to think about moments about the mean $E((X-\mu)^m)$. We call these \textbf{central moments}.

The second central moment should be familiar to you as the \textbf{variance} $\sigma^2$. It has the following equivalent formulation which is computationally useful. $$\Var(X)=E(X^2)-E(X)^2$$
This can be found using the linearity of expectation.

We call the third central moment the \textbf{skewness} and call the fourth central moment the \textbf{kurtosis}.

\begin{definition}[mgf]
	Let $X$ be a random variable such that for some $h>0$, the expectation of $e^{tX}$ exists for $-h<t<h$. The \textbf{moment generating function} (mgf) of $X$ is defined to be the function $M_X(t)=E(e^{tX})$ for $-h<t<h$.
\end{definition}

Clearly, $M_X(0)=1$ for any random variable. Not every random variable has a mgf. For example, the mgf of the Cauchy Distribution with pdf $f(x)=\frac{1}{\pi(1+x^2)}$ is not defined. It can be shown that if the mgf of a random variable exists, then all of its moments exist.

\begin{theorem}[]
	Let $X$ and $Y$ be random variables with mgfs $M_X$ and $M_Y$, respectively, existing in open intervals about 0. Then $F_X(z)=F_Y(z)$ for all $z\in\mathbb R$ if and only if $M_X(t)=M_Y(t)$ in an open interval about 0.
\end{theorem}

\begin{theorem}[]
	Let $X$ be a random variable with mgf $M_X$, and let $a,b\in\mathbb R$ be fixed. Then the mgf of $Y=aX+b$ also exists and is given by $$M_Y(t)=e^{bt}M_X(at).$$
\end{theorem}

\begin{theorem}[]
	Suppose $X$ and $Y$ are independent random variables with mgfs $M_X$ and $M_Y$. Let $a,b\in\mathbb R$ be fixed and define $Z=aX+bY$. Then the mgf of $Z$ exists in an open interval about 0 and is given by
	$$M_Z(t)=M_X(at)M_Y(bt).$$
\end{theorem}

\begin{theorem}[]
	Suppose $X$ is a random variable with mgf $M_X$ and let $M_X^{(m)}(t)=\frac{\mathrm{d}^m}{\dd t^m}M_X(t)$. Then the $m$th moment of $X$ is given by $$E(X^m)=M_X^{(m)}(0).$$
\end{theorem}

The above theorem should make clear why we call mgfs as such. The proof is reliant on the Taylor expansion of $e^{tX}$. We use the linearity of expectation, which will be stated formally in a later section.
\begin{align*}
	M_X(t)&=E(e^{tX})\\
	&=E\left(\sum_{n=0}^\infty \frac{t^n}{n!}X^n\right)\\
	&=\sum_{n=0}^\infty \frac{t^n}{n!}E(X^n)
\end{align*}

\subsection{Distributions}

We reintroduce some special distributions, starting with those of the discrete kind.

\begin{definition}[binomial random variable]
	Assume a sequence of $n$ Bernouilli trials each with probability of success $p$ and let $X$ be the number of successes. Then $X$ is a \textbf{binomial random variable} with pmf $$p_X(x)=\begin{cases}
		\binom{n}{x}p^x(1-p)^{n-x} & \text{for $x=0,1,\hdots,n$}\\
		0 & \text{otherwise}
	\end{cases}$$
	We write $X\sim b(n,p)$.
\end{definition}

If $X\sim b(n,p)$, $X$ has support $\{0,1,\hdots,n\}$, mean $\mu=np$, variance $\sigma^2=np(1-p)$ and mgf $M_X(t)=(1-p+pe^t)^n$.

\begin{definition}[negative binomial random variable]
	Assume a sequence of Bernouilli trials each with probability of success $p$ is performed until the $r$th success occurs. Let $Y$ be the number of trials required. Then $Y$ is a \textbf{negative binomial random variable} with pmf $$p_Y(y)=\begin{cases}
		\binom{y+r-1}{y-1}p^r(1-p)^y & \text{for $y=0,1,\hdots$}\\
		0 & \text{otherwise}
	\end{cases}$$
	We write $Y\sim \mathop{nb}(r,p)$.
\end{definition}

If $Y\sim \mathop{nb}(r,p)$, $Y$ has support $\mathbb Z_{\geq 0}$, mean $\mu=\frac{pr}{1-p}$, variance $\sigma^2=\frac{pr}{(1-p)^2}$ and mgf $M_Y(t)=\left(\frac{1-p}{1-pe^t}\right)$ with $t<-\ln p$.

Taking $r=1$, we obtain the geometric distribution.

\begin{definition}[Poisson random variable]
	A discrete random variable $X$ is a \textbf{Poisson random variable} if its pmf has the form $$p_X(x)=\begin{cases}
		\frac{\lambda^xe^{-\lambda}}{x!} & \text{for $x=0,1,\hdots$}\\
		0 & \text{otherwise}
	\end{cases}$$
	where $\lambda\in\mathbb R_{\geq 0}$. We write $X\sim \operatorname{Pois}(\lambda)$.
\end{definition}

If $X\sim \operatorname{Pois}(\lambda)$, $X$ has support $\mathbb Z_{\geq 0}$, mean $\mu=\lambda$, variance $\sigma^2=\lambda$ and mgf $M_X(t)=\exp(\lambda(e^t-1))$.

We now recall some continuous distributions.

\begin{definition}[uniform random variable]
	A continuous random variable $X$ is said to be a \textbf{uniform random variable} if it has pdf
	$$p_X(x)=\begin{cases}
		\frac{1}{b-a} & \text{for $x\in[a,b])$}\\
		0 & \text{otherwise}
	\end{cases}$$
	where $a,b\in\mathbb R$ are fixed. We write $X\sim U(a,b)$.
\end{definition}

If $X\sim U(a,b)$, $X$ has support $[a,b]$, mean $\mu=\frac{a+b}{2}$, variance $\sigma^2=\frac{(b-a)^2}{12}$ and mgf $M_X(t)=\begin{cases}
	\frac{e^{tb}-e^{ta}}{t(b-a)} & \text{for $t\neq 0$}\\
	1 & \text{for $t= 0$}
\end{cases}$.

\begin{definition}[normal random variable]
	A continuous random variable $X$ is said to be a \textbf{normal random variable} with parameters $\mu\in\mathbb R$ and $\sigma^2>0$ if its pdf has the form
	$$f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac 12\left(\frac{x-\mu}{\sigma}\right)^2}.$$
	We write $X\sim N(\mu,\sigma^2)$.
\end{definition}

If $X\sim N(\mu,\sigma^2)$, $X$ has support $\mathbb R$, mean $\mu$, variance $\sigma^2$ and mgf $M_X(t)=e^{\mu t+\frac{\sigma^2 t^2}{2}}$.

The derivation of this mgf is left as an exercise.

\begin{theorem}[]
	Let $X_1,\hdots,X_n$ be IID random variables such that $X_i\sim N(\mu_i,\sigma_i^2)$ for each $i=1,\hdots,n$. Let $Y=\sum_{i=1}^na_iX_i$ for some set of real constants $\{a_1,\hdots,a_n\}$. Then $Y$ is also normally distributed with
$$E(Y)=\sum_{i=1}^na_i\mu_i\quad\text{and}\quad\Var(Y)=\sum_{i=1}^na_i^2\sigma_i^2.$$
\end{theorem}

\begin{definition}[gamma random variable]
	A continuous random variable $X$ is said to be a \textbf{gamma random variable} with parameters $\alpha,\beta>0$ if its pdf has the form
	$$f_X(x)=\begin{cases}
		\frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha - 1} e^{-\beta x } & \text{for $x\in\mathbb R_{>0}$}\\
		0 & \text{otherwise}
	\end{cases}.$$
	We write $X\sim \Gamma(\alpha,\beta)$.
\end{definition}

Taking $\alpha=1$ yields the exponential distribution.

If $X\sim \Gamma(\alpha,\beta)$, $X$ has support $\mathbb R_{>0}$, mean $\mu=\frac{\alpha}{\beta}$, variance $\sigma^2=\frac{\alpha}{\beta^2}$ and mgf $M_X(t)=\left(1 - \frac{t}{\beta}\right)^{-\alpha}$ for $t < \beta$.


\begin{definition}[beta random variable]
	A continuous random variable $X$ is said to be a \textbf{beta random variable} with parameters $\alpha,\beta>0$ if its pdf has the form
	$$f_X(x)=\begin{cases}
		\frac{x^{\alpha-1}(1-x)^{\beta-1}} {\mathrm{B}(\alpha,\beta)} & \text{for $x\in(0,1)$}\\
		0 & \text{otherwise}
	\end{cases}$$
	where $\mathrm{B}(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$. We write $X\sim \operatorname{Beta}(\alpha,\beta)$.
\end{definition}

If $X\sim \operatorname{Beta}(\alpha,\beta)$, $X$ has support $(0,1)$, mean $\mu=\frac{\alpha}{\alpha + \beta}$, variance $\sigma^2=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$ and mgf $M_X(t)=1+\sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} \frac{\alpha+r}{\alpha+\beta+r} \right) \frac{t^k}{k!}$.
